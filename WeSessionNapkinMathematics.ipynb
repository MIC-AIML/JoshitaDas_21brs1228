{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Gk1AgGI1ZBl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mental model of neural network"
      ],
      "metadata": {
        "id": "Upi0CeRk1b81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = [0.2, 0.5, 0.4, 0.7]\n",
        "# We randomly initialize the weights (values) for the hidden layer... We will\n",
        "# need to \"train\" to make these weights give us the output layers we desire. We\n",
        "# will cover that shortly!\n",
        "hidden_layer = [0.98, 0.4, 0.86, -0.08]\n",
        "\n",
        "output_neuron = 0\n",
        "# This is really matrix multiplication. We explicitly _do not_ use a\n",
        "# matrix/tensor, because they add overhead to understanding what happens here\n",
        "# unless you work with them every day--which you probably don't. More on using\n",
        "# matrices later.\n",
        "for index, input_neuron in enumerate(input_layer):\n",
        "    output_neuron += input_neuron * hidden_layer[index]\n",
        "print(output_neuron)\n",
        "# => 0.68"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZZZZGob1czK",
        "outputId": "41a718eb-7259-4c76-847b-20aa0110ece7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6839999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 1: CREATING A DATASET\n"
      ],
      "metadata": {
        "id": "LLLQvdIQ_bUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "rectangles = []\n",
        "rectangle_average = []\n",
        "\n",
        "for i in range(0, 1000):\n",
        "    # Generate a 2x2 rectangle [0.1, 0.8, 0.6, 1.0]\n",
        "    rectangle = [round(random.random(), 1),\n",
        "                 round(random.random(), 1),\n",
        "                 round(random.random(), 1),\n",
        "                 round(random.random(), 1)]\n",
        "    rectangles.append(rectangle)\n",
        "    # Take the _actual_ average for our training dataset!\n",
        "    rectangle_average.append(sum(rectangle) / 4)"
      ],
      "metadata": {
        "id": "aP5X1jYY_fpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 2: MEAN SQUARED ERROR"
      ],
      "metadata": {
        "id": "Gkd1L5_g_g11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Take the average of all the differences squared!\n",
        "# This calculates how \"wrong\" our predictions are.\n",
        "# This is called our \"loss\".\n",
        "def mean_squared_error(actual, expected):\n",
        "    error_sum = 0\n",
        "    for a, b in zip(actual, expected):\n",
        "        error_sum += (a - b) ** 2\n",
        "    return error_sum / len(actual)\n",
        "\n",
        "print(mean_squared_error([1.], [2.]))\n",
        "# => 1.0\n",
        "print(mean_squared_error([1.], [3.]))\n",
        "# => 4.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-GOW-Ep_v3Z",
        "outputId": "3aec4b9a-ff61-4e55-9349-d75a39462fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "implementing train"
      ],
      "metadata": {
        "id": "J0vAAXPpAMD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(rectangle, hidden_layer):\n",
        "    output_neuron = 0.\n",
        "    for index, input_neuron in enumerate(rectangle):\n",
        "        output_neuron += input_neuron * hidden_layer[index]\n",
        "    return output_neuron\n",
        "\n",
        "def train(rectangles, hidden_layer):\n",
        "  outputs = []\n",
        "  for rectangle in rectangles:\n",
        "      output = model(rectangle, hidden_layer)\n",
        "      outputs.append(output)\n",
        "  return outputs\n",
        "\n",
        "hidden_layer = [0.98, 0.4, 0.86, -0.08]\n",
        "outputs = train(rectangles, hidden_layer)\n",
        "\n",
        "print(outputs[0:10])\n",
        "# [1.472, 0.7, 1.369, 0.8879, 1.392, 1.244, 0.644, 1.1179, 0.474, 1.54]\n",
        "print(rectangle_average[0:10])\n",
        "# [0.575, 0.45, 0.549, 0.35, 0.525, 0.475, 0.425, 0.65, 0.4, 0.575]\n",
        "mean_squared_error(outputs, rectangle_average)\n",
        "# 0.4218"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUADwJyCAXLJ",
        "outputId": "8fa9ff26-852d-416a-9b7b-8442e43cc4d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9359999999999999, 1.026, 1.016, 1.424, 1.248, 1.186, 0.41200000000000003, 1.316, 0.716, 1.774]\n",
            "[0.55, 0.525, 0.425, 0.55, 0.675, 0.5249999999999999, 0.22500000000000003, 0.5, 0.44999999999999996, 0.725]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4345181889999996"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "updating hidden layer with gradient descent"
      ],
      "metadata": {
        "id": "RXGt_3oiAZBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error(\n",
        "  train(rectangles, hidden_layer),\n",
        "  rectangle_average\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDJJnIxfAeqA",
        "outputId": "fe3a7ef0-6226-43d0-88a5-e856203db80a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4345181889999996"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "introducing gradient descent"
      ],
      "metadata": {
        "id": "wP35ZZnKAprB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(rectangle, hidden_layer):\n",
        "    output_neuron = 0.\n",
        "    for index, input_neuron in enumerate(rectangle):\n",
        "        output_neuron += input_neuron * hidden_layer[index]\n",
        "    return output_neuron\n",
        "\n",
        "def train(rectangles, hidden_layer):\n",
        "  outputs = []\n",
        "  for rectangle in rectangles:\n",
        "      output = model(rectangle, hidden_layer)\n",
        "      outputs.append(output)\n",
        "\n",
        "  mean_squared_error(outputs, rectangle_average)\n",
        "\n",
        "  # We go through all the weights in the hidden layer. These correspond to all\n",
        "  # the weights of the function we're trying to minimize the value of: our\n",
        "  # model, respective of its loss (how wrong it is).\n",
        "  # \n",
        "  # For each of the weights, we want to increase/decrease it based on the slope.\n",
        "  # Exactly like we showed in the one-weight example above with just x. Now\n",
        "  # we just have 4 values instead of 1! Big models have billions.\n",
        "  for index, _ in enumerate(hidden_layer):\n",
        "    learning_rate = 0.1\n",
        "    # But... how do we get the slope/derivative?!\n",
        "    hidden_layer[index] -= learning_rate * hidden_layer[index].slope\n",
        "\n",
        "  return outputs\n",
        "\n",
        "hidden_layer = [0.98, 0.4, 0.86, -0.08]\n",
        "train(rectangles, hidden_layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "nm4k3OYHAtAd",
        "outputId": "d8dba59a-2598-43ef-bf13-0736b3baf482"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-548bd18f7382>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mhidden_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.98\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.86\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.08\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrectangles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'rectangles' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculating slope"
      ],
      "metadata": {
        "id": "lSqrhkGqA6cy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# A tensor is a matrix in PyTorch. It is the fundamental data-structure of neural\n",
        "# networks. Here we say PyTorch, please keep track of the gradient/derivative\n",
        "# as I do all kinds of things to the parameter(s) of this tensor.\n",
        "x = torch.tensor(2., requires_grad=True)\n",
        "\n",
        "# At this point we're applying our function f(x) = x^2.\n",
        "y = x ** 2\n",
        "\n",
        "# This tells `autograd` to compute the derivative values for all the parameters\n",
        "# involved. Backward is neural network jargon for this operation, which we'll\n",
        "# explain momentarily.\n",
        "y.backward()\n",
        "\n",
        "# And show us the lovely gradient/derivative, which is 4! Sick.\n",
        "print(x.grad)\n",
        "# => 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcCkry0MA8uU",
        "outputId": "206df3b8-4ac2-4edc-d94d-ca805d1de515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "https://colab.research.google.com/drive/1qPtXZQhuXtqBBtG8ypWgpag0cFGlC6rS#scrollTo=sk1s9aJryQuo"
      ],
      "metadata": {
        "id": "8fcxWAaBA_mT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}